{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/Cl5B7pBmIo2lUrT5i8KR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6e80bb9050e9488e999dcb1942028d4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8af8ff0145884430b39d8aaf0f57f04f",
              "IPY_MODEL_ce5269dd6541468cab988253a2e1a13f",
              "IPY_MODEL_66206c1c808d48eb9f1644a75c86edc8"
            ],
            "layout": "IPY_MODEL_21a7be6c2da34df2aed7507a5c3cdabb"
          }
        },
        "8af8ff0145884430b39d8aaf0f57f04f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a797f1d8eddc4b338dbbc20a929e5cf1",
            "placeholder": "​",
            "style": "IPY_MODEL_cc0754f3a21a42cb9423d0e4ef72e271",
            "value": "100%"
          }
        },
        "ce5269dd6541468cab988253a2e1a13f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3867128b29df4209ad32faedb8a5c966",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef67f544efed4ff7b0b84e83cce71964",
            "value": 25
          }
        },
        "66206c1c808d48eb9f1644a75c86edc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87d1330642c3480b83b18e5b21e6a075",
            "placeholder": "​",
            "style": "IPY_MODEL_fbe93ace0e144e14b2afc80e284b8eec",
            "value": " 25/25 [00:02&lt;00:00,  8.46it/s]"
          }
        },
        "21a7be6c2da34df2aed7507a5c3cdabb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a797f1d8eddc4b338dbbc20a929e5cf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc0754f3a21a42cb9423d0e4ef72e271": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3867128b29df4209ad32faedb8a5c966": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef67f544efed4ff7b0b84e83cce71964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "87d1330642c3480b83b18e5b21e6a075": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbe93ace0e144e14b2afc80e284b8eec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2403A51L33/PfDS-PROJECT/blob/main/REINFORCEMENT%20LEARNING%20ALGORITHMS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "6e80bb9050e9488e999dcb1942028d4e",
            "8af8ff0145884430b39d8aaf0f57f04f",
            "ce5269dd6541468cab988253a2e1a13f",
            "66206c1c808d48eb9f1644a75c86edc8",
            "21a7be6c2da34df2aed7507a5c3cdabb",
            "a797f1d8eddc4b338dbbc20a929e5cf1",
            "cc0754f3a21a42cb9423d0e4ef72e271",
            "3867128b29df4209ad32faedb8a5c966",
            "ef67f544efed4ff7b0b84e83cce71964",
            "87d1330642c3480b83b18e5b21e6a075",
            "fbe93ace0e144e14b2afc80e284b8eec"
          ]
        },
        "id": "NyX6uslEem4m",
        "outputId": "90b4e509-c4b0-4c6d-f960-127258c885d2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e80bb9050e9488e999dcb1942028d4e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done. Artifacts in: ./rl_outputs\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier, export_text\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "try:\n",
        "    import shap\n",
        "    SHAP_AVAILABLE = True\n",
        "except Exception:\n",
        "    SHAP_AVAILABLE = False\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "OUTDIR = \"./rl_outputs\"\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "\n",
        "DATA_PATH = \"/content/realistic_drug_labels_side_effects.csv\"\n",
        "\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    alt = \"./realistic_drug_labels_side_effects.csv\"\n",
        "    if os.path.exists(alt):\n",
        "        DATA_PATH = alt\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"Dataset not found at {DATA_PATH} or {alt}\")\n",
        "\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "def to_three_bins(x):\n",
        "    try:\n",
        "        val = float(x)\n",
        "        return val\n",
        "    except:\n",
        "        s = str(x).strip().lower()\n",
        "        mapping = {\"low\":0, \"mild\":0, \"moderate\":1, \"medium\":1, \"high\":2, \"severe\":2}\n",
        "        return mapping.get(s, 1)\n",
        "\n",
        "if pd.api.types.is_numeric_dtype(df[\"side_effect_severity\"]):\n",
        "    q = np.quantile(df[\"side_effect_severity\"], [0.33, 0.66])\n",
        "    def bin_numeric(v):\n",
        "        if v <= q[0]: return 0\n",
        "        if v <= q[1]: return 1\n",
        "        return 2\n",
        "    y = df[\"side_effect_severity\"].apply(bin_numeric).astype(int).values\n",
        "else:\n",
        "    approx = df[\"side_effect_severity\"].apply(to_three_bins).astype(float)\n",
        "    q = np.quantile(approx, [0.33, 0.66])\n",
        "    def bin_numeric(v):\n",
        "        if v <= q[0]: return 0\n",
        "        if v <= q[1]: return 1\n",
        "        return 2\n",
        "    y = approx.apply(bin_numeric).astype(int).values\n",
        "\n",
        "num_classes = 3\n",
        "class_names = [\"low\", \"moderate\", \"high\"]\n",
        "\n",
        "text_cols = [\"indications\", \"side_effects\", \"contraindications\", \"warnings\"]\n",
        "num_cols = [\"dosage_mg\", \"price_usd\", \"approval_year\"]\n",
        "cat_cols = [\"drug_class\", \"administration_route\", \"approval_status\", \"manufacturer\"]\n",
        "\n",
        "text_cols = [c for c in text_cols if c in df.columns]\n",
        "num_cols = [c for c in num_cols if c in df.columns]\n",
        "cat_cols = [c for c in cat_cols if c in df.columns]\n",
        "\n",
        "for c in text_cols:\n",
        "    df[c] = df[c].fillna(\"\")\n",
        "\n",
        "X_text = df[text_cols].apply(lambda r: \" \".join([str(v) for v in r.values]), axis=1)\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2), min_df=2)\n",
        "X_text_mat = tfidf.fit_transform(X_text)\n",
        "\n",
        "X_num = df[num_cols].fillna(df[num_cols].median()) if num_cols else pd.DataFrame(index=df.index)\n",
        "X_cat = df[cat_cols].fillna(\"UNK\") if cat_cols else pd.DataFrame(index=df.index)\n",
        "\n",
        "if not X_num.empty:\n",
        "    scaler = StandardScaler()\n",
        "    X_num_scaled = scaler.fit_transform(X_num.values)\n",
        "else:\n",
        "    X_num_scaled = np.zeros((len(df), 0))\n",
        "\n",
        "if not X_cat.empty:\n",
        "    X_cat_dummies = pd.get_dummies(X_cat, drop_first=True, dtype=np.float32)\n",
        "else:\n",
        "    X_cat_dummies = pd.DataFrame(index=df.index)\n",
        "\n",
        "from scipy import sparse\n",
        "X_other = np.hstack([X_num_scaled, X_cat_dummies.values]) if X_cat_dummies.shape[1] > 0 else X_num_scaled\n",
        "X = sparse.hstack([X_text_mat, sparse.csr_matrix(X_other)], format=\"csr\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=SEED, stratify=y\n",
        ")\n",
        "\n",
        "R = np.array([\n",
        "    [ 1.0,      -0.2,   -0.5],\n",
        "    [-0.2,       1.0,   -0.2],\n",
        "    [-2.0,      -0.5,    1.2],\n",
        "])\n",
        "\n",
        "def batch_csr_to_torch(X_csr):\n",
        "    X_coo = X_csr.tocoo()\n",
        "    indices = torch.tensor(np.vstack((X_coo.row, X_coo.col)), dtype=torch.long)\n",
        "    values = torch.tensor(X_coo.data, dtype=torch.float32)\n",
        "    shape = torch.Size(X_coo.shape)\n",
        "    return torch.sparse_coo_tensor(indices, values, shape).to_dense()\n",
        "\n",
        "def sample_minibatch(X_csr, y_arr, batch_size=64):\n",
        "    idx = np.random.randint(0, X_csr.shape[0], size=batch_size)\n",
        "    Xb = X_csr[idx]\n",
        "    yb = y_arr[idx]\n",
        "    return batch_csr_to_torch(Xb), torch.tensor(yb, dtype=torch.long)\n",
        "\n",
        "def compute_reward(y_true, a):\n",
        "    return R[y_true, a]\n",
        "\n",
        "def evaluate_policy(pred, y_true):\n",
        "    cm = confusion_matrix(y_true, pred, labels=[0,1,2])\n",
        "    report = classification_report(y_true, pred, target_names=class_names, output_dict=True)\n",
        "    return cm, report\n",
        "\n",
        "class EpsilonGreedyBandit:\n",
        "    def __init__(self, n_actions=3, eps=0.1):\n",
        "        self.nA = n_actions\n",
        "        self.eps = eps\n",
        "        self.counts = np.zeros(n_actions, dtype=int)\n",
        "        self.values = np.zeros(n_actions, dtype=float)\n",
        "\n",
        "    def select(self):\n",
        "        if np.random.rand() < self.eps:\n",
        "            return np.random.randint(self.nA)\n",
        "        return int(np.argmax(self.values))\n",
        "\n",
        "    def update(self, a, r):\n",
        "        self.counts[a] += 1\n",
        "        n = self.counts[a]\n",
        "        self.values[a] += (r - self.values[a]) / n\n",
        "\n",
        "class UCB1Bandit:\n",
        "    def __init__(self, n_actions=3):\n",
        "        self.nA = n_actions\n",
        "        self.counts = np.zeros(n_actions, dtype=int)\n",
        "        self.values = np.zeros(n_actions, dtype=float)\n",
        "        self.t = 0\n",
        "\n",
        "    def select(self):\n",
        "        self.t += 1\n",
        "        for a in range(self.nA):\n",
        "            if self.counts[a] == 0:\n",
        "                return a\n",
        "        ucb = self.values + np.sqrt(2*np.log(self.t)/self.counts)\n",
        "        return int(np.argmax(ucb))\n",
        "\n",
        "    def update(self, a, r):\n",
        "        self.counts[a] += 1\n",
        "        n = self.counts[a]\n",
        "        self.values[a] += (r - self.values[a]) / n\n",
        "\n",
        "class ThompsonBandit:\n",
        "    def __init__(self, n_actions=3):\n",
        "        self.nA = n_actions\n",
        "        self.mu = np.zeros(n_actions)\n",
        "        self.lambda_prec = np.ones(n_actions)  # precision\n",
        "        self.tau = 1.0\n",
        "\n",
        "    def select(self):\n",
        "        samples = np.random.normal(self.mu, 1.0/np.sqrt(self.lambda_prec))\n",
        "        return int(np.argmax(samples))\n",
        "\n",
        "    def update(self, a, r):\n",
        "        self.lambda_prec[a] += self.tau\n",
        "        self.mu[a] = (self.mu[a]*(self.lambda_prec[a]-self.tau) + r) / self.lambda_prec[a]\n",
        "\n",
        "class LinUCB:\n",
        "    def __init__(self, d, n_actions=3, alpha=1.0, l2=1.0):\n",
        "        self.nA = n_actions\n",
        "        self.alpha = alpha\n",
        "        self.A = [l2 * np.eye(d) for _ in range(n_actions)]\n",
        "        self.b = [np.zeros((d,)) for _ in range(n_actions)]\n",
        "\n",
        "    def select(self, x):\n",
        "        p = np.zeros(self.nA)\n",
        "        for a in range(self.nA):\n",
        "            A_inv = np.linalg.inv(self.A[a])\n",
        "            theta = A_inv @ self.b[a]\n",
        "            p[a] = theta @ x + self.alpha * np.sqrt(x @ A_inv @ x)\n",
        "        return int(np.argmax(p))\n",
        "\n",
        "    def update(self, x, a, r):\n",
        "        self.A[a] += np.outer(x, x)\n",
        "        self.b[a] += r * x\n",
        "\n",
        "class LogisticTS:\n",
        "    def __init__(self, d, n_actions=3, l2=1.0):\n",
        "        self.nA = n_actions\n",
        "        self.d = d\n",
        "        self.l2 = l2\n",
        "        self.W = np.zeros((n_actions, d))\n",
        "\n",
        "    def _sigmoid(self, z):\n",
        "        return 1/(1+np.exp(-z))\n",
        "\n",
        "    def select(self, x):\n",
        "        noise = np.random.normal(0, 0.1, size=self.W.shape)\n",
        "        W_s = self.W + noise\n",
        "        logits = W_s @ x\n",
        "        return int(np.argmax(logits))\n",
        "\n",
        "    def update(self, x, a, r):\n",
        "        y = 1 if r > 0 else 0\n",
        "        z = self.W[a] @ x\n",
        "        p = self._sigmoid(z)\n",
        "        grad = (y - p) * x - self.l2 * self.W[a]\n",
        "        self.W[a] += 0.05 * grad\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, hidden=256):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden, out_dim),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class DQNAgent:\n",
        "    def __init__(self, in_dim, n_actions, gamma=0.99, lr=1e-3, eps=0.1):\n",
        "        self.q = MLP(in_dim, n_actions, hidden=256)\n",
        "        self.target = MLP(in_dim, n_actions, hidden=256)\n",
        "        self.target.load_state_dict(self.q.state_dict())\n",
        "        self.gamma = gamma\n",
        "        self.optim = optim.Adam(self.q.parameters(), lr=lr)\n",
        "        self.eps = eps\n",
        "        self.nA = n_actions\n",
        "        self.losses = []\n",
        "\n",
        "    def act(self, x):\n",
        "        if np.random.rand() < self.eps:\n",
        "            return np.random.randint(self.nA)\n",
        "        with torch.no_grad():\n",
        "            q = self.q(x)\n",
        "            return int(torch.argmax(q, dim=-1).item())\n",
        "\n",
        "    def update(self, x, a, r, xn, done):\n",
        "        q = self.q(x)[0, a]\n",
        "        with torch.no_grad():\n",
        "            qn = self.target(xn).max(dim=-1).values\n",
        "            y = r + (0 if done else self.gamma * qn)\n",
        "        loss = F.mse_loss(q, y)\n",
        "        self.optim.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optim.step()\n",
        "        self.losses.append(loss.item())\n",
        "\n",
        "    def soft_update(self, tau=0.01):\n",
        "        for t, s in zip(self.target.parameters(), self.q.parameters()):\n",
        "            t.data.copy_((1 - tau) * t.data + tau * s.data)\n",
        "\n",
        "class PolicyNet(nn.Module):\n",
        "    def __init__(self, in_dim, n_actions, hidden=256):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden, n_actions),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return F.log_softmax(self.net(x), dim=-1)\n",
        "\n",
        "class ValueNet(nn.Module):\n",
        "    def __init__(self, in_dim, hidden=256):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden, 1),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class REINFORCEAgent:\n",
        "    def __init__(self, in_dim, n_actions, lr=1e-3):\n",
        "        self.policy = PolicyNet(in_dim, n_actions)\n",
        "        self.optim = optim.Adam(self.policy.parameters(), lr=lr)\n",
        "\n",
        "    def act(self, x):\n",
        "        with torch.no_grad():\n",
        "            logp = self.policy(x)\n",
        "            p = torch.exp(logp)\n",
        "            a = torch.multinomial(p, num_samples=1)\n",
        "            return int(a.item())\n",
        "\n",
        "    def update(self, x, a, G):\n",
        "        logp = self.policy(x)[0, a]\n",
        "        loss = -logp * G\n",
        "        self.optim.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optim.step()\n",
        "\n",
        "class A2CAgent:\n",
        "    def __init__(self, in_dim, n_actions, lr=1e-3, gamma=0.99):\n",
        "        self.policy = PolicyNet(in_dim, n_actions)\n",
        "        self.value = ValueNet(in_dim)\n",
        "        self.op = optim.Adam(list(self.policy.parameters()) + list(self.value.parameters()), lr=lr)\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def act(self, x):\n",
        "        with torch.no_grad():\n",
        "            logp = self.policy(x)\n",
        "            p = torch.exp(logp)\n",
        "            a = torch.multinomial(p, num_samples=1)\n",
        "            return int(a.item())\n",
        "\n",
        "    def update(self, x, a, r, xn, done):\n",
        "        V = self.value(x)\n",
        "        with torch.no_grad():\n",
        "            Vn = self.value(xn)\n",
        "            target = r + (0 if done else self.gamma * Vn)\n",
        "            adv = target - V\n",
        "        logp = self.policy(x)[0, a]\n",
        "        actor_loss = -logp * adv.detach()\n",
        "        critic_loss = F.mse_loss(V, target)\n",
        "        loss = actor_loss + critic_loss\n",
        "        self.op.zero_grad()\n",
        "        loss.backward()\n",
        "        self.op.step()\n",
        "\n",
        "class BehaviorCloning:\n",
        "    def __init__(self, in_dim, n_actions, lr=1e-3):\n",
        "        self.net = MLP(in_dim, n_actions)\n",
        "        self.op = optim.Adam(self.net.parameters(), lr=lr)\n",
        "\n",
        "    def fit(self, X_t, y_t, steps=500, bs=64):\n",
        "        N = X_t.shape[0]\n",
        "        X_dense = batch_csr_to_torch(X_t)\n",
        "        y_t = torch.tensor(y_t, dtype=torch.long)\n",
        "        for _ in range(steps):\n",
        "            idx = np.random.randint(0, N, size=bs)\n",
        "            xb = X_dense[idx]\n",
        "            yb = y_t[idx]\n",
        "            logits = self.net(xb)\n",
        "            loss = F.cross_entropy(logits, yb)\n",
        "            self.op.zero_grad()\n",
        "            loss.backward()\n",
        "            self.op.step()\n",
        "        return self\n",
        "\n",
        "    def predict(self, X_csr):\n",
        "        with torch.no_grad():\n",
        "            Xd = batch_csr_to_torch(X_csr)\n",
        "            logits = self.net(Xd)\n",
        "            return logits.argmax(dim=-1).cpu().numpy()\n",
        "\n",
        "class CQLlite(DQNAgent):\n",
        "    def update(self, x, a, r, xn, done):\n",
        "        q_all = self.q(x)\n",
        "        q = q_all[0, a]\n",
        "        with torch.no_grad():\n",
        "            qn = self.target(xn).max(dim=-1).values\n",
        "            y = r + (0 if done else self.gamma * qn)\n",
        "        cql_penalty = 1e-3 * (q_all.pow(2).mean())\n",
        "        loss = F.mse_loss(q, y) + cql_penalty\n",
        "        self.optim.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optim.step()\n",
        "\n",
        "def train_non_contextual_bandits():\n",
        "    y_tr = y_train\n",
        "    bandits = {\n",
        "        \"eps_greedy\": EpsilonGreedyBandit(n_actions=num_classes, eps=0.1),\n",
        "        \"ucb1\": UCB1Bandit(n_actions=num_classes),\n",
        "        \"thompson\": ThompsonBandit(n_actions=num_classes),\n",
        "    }\n",
        "    steps = min(5000, len(y_tr)*2)\n",
        "    results = {}\n",
        "    for name, agent in bandits.items():\n",
        "        for _ in range(steps):\n",
        "            a = agent.select()\n",
        "            yt = int(y_tr[np.random.randint(0, len(y_tr))])\n",
        "            r = compute_reward(yt, a)\n",
        "            agent.update(a, r)\n",
        "        best_action = int(np.argmax(agent.values if hasattr(agent, \"values\") else agent.mu))\n",
        "        pred = np.full_like(y_test, best_action)\n",
        "        cm, rep = evaluate_policy(pred, y_test)\n",
        "        results[name] = {\"confusion_matrix\": cm.tolist(), \"report\": rep}\n",
        "    return results\n",
        "\n",
        "def train_contextual_bandits():\n",
        "    Xtr_dense = batch_csr_to_torch(X_train)\n",
        "    Xte_dense = batch_csr_to_torch(X_test)\n",
        "    d = Xtr_dense.shape[1]\n",
        "\n",
        "    linucb = LinUCB(d, n_actions=num_classes, alpha=0.5, l2=1.0)\n",
        "    logts = LogisticTS(d, n_actions=num_classes, l2=1.0)\n",
        "\n",
        "    T = min(2000, Xtr_dense.shape[0]*2)\n",
        "    for _ in range(T):\n",
        "        i = np.random.randint(0, Xtr_dense.shape[0])\n",
        "        x = Xtr_dense[i].numpy()\n",
        "        ytrue = int(y_train[i])\n",
        "        a1 = linucb.select(x); r1 = compute_reward(ytrue, a1); linucb.update(x, a1, r1)\n",
        "        a2 = logts.select(x);  r2 = compute_reward(ytrue, a2); logts.update(x, a2, r2)\n",
        "\n",
        "    def eval_agent(agent, denseX):\n",
        "        preds = []\n",
        "        for i in range(denseX.shape[0]):\n",
        "            x = denseX[i].numpy()\n",
        "            preds.append(agent.select(x))\n",
        "        return np.array(preds)\n",
        "\n",
        "    pred_linucb = eval_agent(linucb, Xte_dense)\n",
        "    pred_logts = eval_agent(logts, Xte_dense)\n",
        "\n",
        "    results = {}\n",
        "    for name, pred in [(\"linucb\", pred_linucb), (\"logistic_ts\", pred_logts)]:\n",
        "        cm, rep = evaluate_policy(pred, y_test)\n",
        "        results[name] = {\"confusion_matrix\": cm.tolist(), \"report\": rep}\n",
        "    return results\n",
        "\n",
        "def train_deep_rl():\n",
        "    Xtr_dense = batch_csr_to_torch(X_train)\n",
        "    Xte_dense = batch_csr_to_torch(X_test)\n",
        "    in_dim = Xtr_dense.shape[1]\n",
        "\n",
        "    # DQN\n",
        "    dqn = DQNAgent(in_dim, num_classes, lr=1e-3, eps=0.1)\n",
        "    for _ in range(min(2000, Xtr_dense.shape[0]*2)):\n",
        "        i = np.random.randint(0, Xtr_dense.shape[0])\n",
        "        x = Xtr_dense[i].unsqueeze(0)\n",
        "        ytrue = int(y_train[i])\n",
        "        a = dqn.act(x)\n",
        "        r = torch.tensor([compute_reward(ytrue, a)], dtype=torch.float32)\n",
        "        xn = Xtr_dense[np.random.randint(0, Xtr_dense.shape[0])].unsqueeze(0)\n",
        "        dqn.update(x, a, r, xn, done=True)\n",
        "        dqn.soft_update(0.01)\n",
        "    with torch.no_grad():\n",
        "        q_logits = dqn.q(Xte_dense)\n",
        "        pred_dqn = q_logits.argmax(dim=-1).cpu().numpy()\n",
        "    cm_dqn, rep_dqn = evaluate_policy(pred_dqn, y_test)\n",
        "\n",
        "    rei = REINFORCEAgent(in_dim, num_classes, lr=1e-3)\n",
        "    for _ in range(min(2000, Xtr_dense.shape[0]*2)):\n",
        "        i = np.random.randint(0, Xtr_dense.shape[0])\n",
        "        x = Xtr_dense[i].unsqueeze(0)\n",
        "        ytrue = int(y_train[i])\n",
        "        a = rei.act(x)\n",
        "        r = compute_reward(ytrue, a)\n",
        "        G = torch.tensor([r], dtype=torch.float32)\n",
        "        rei.update(x, a, G)\n",
        "    with torch.no_grad():\n",
        "        logp = rei.policy(Xte_dense)\n",
        "        pred_rei = torch.exp(logp).argmax(dim=-1).cpu().numpy()\n",
        "    cm_rei, rep_rei = evaluate_policy(pred_rei, y_test)\n",
        "\n",
        "    a2c = A2CAgent(in_dim, num_classes, lr=1e-3)\n",
        "    for _ in range(min(2000, Xtr_dense.shape[0]*2)):\n",
        "        i = np.random.randint(0, Xtr_dense.shape[0])\n",
        "        x = Xtr_dense[i].unsqueeze(0)\n",
        "        ytrue = int(y_train[i])\n",
        "        a = a2c.act(x)\n",
        "        r = torch.tensor([compute_reward(ytrue, a)], dtype=torch.float32)\n",
        "        xn = Xtr_dense[np.random.randint(0, Xtr_dense.shape[0])].unsqueeze(0)\n",
        "        a2c.update(x, a, r, xn, done=True)\n",
        "    with torch.no_grad():\n",
        "        logp = a2c.policy(Xte_dense)\n",
        "        pred_a2c = torch.exp(logp).argmax(dim=-1).cpu().numpy()\n",
        "    cm_a2c, rep_a2c = evaluate_policy(pred_a2c, y_test)\n",
        "\n",
        "    results = {\n",
        "        \"dqn\": {\"confusion_matrix\": cm_dqn.tolist(), \"report\": rep_dqn},\n",
        "        \"reinforce\": {\"confusion_matrix\": cm_rei.tolist(), \"report\": rep_rei},\n",
        "        \"a2c\": {\"confusion_matrix\": cm_a2c.tolist(), \"report\": rep_a2c},\n",
        "    }\n",
        "    return results, rei.policy, Xtr_dense, Xte_dense\n",
        "\n",
        "def train_offline_rl():\n",
        "    Xtr_dense = batch_csr_to_torch(X_train)\n",
        "    Xte_dense = batch_csr_to_torch(X_test)\n",
        "    in_dim = Xtr_dense.shape[1]\n",
        "\n",
        "    bc = BehaviorCloning(in_dim, num_classes, lr=1e-3)\n",
        "    bc.fit(X_train, y_train, steps=750, bs=64)\n",
        "    pred_bc = bc.predict(X_test)\n",
        "    cm_bc, rep_bc = evaluate_policy(pred_bc, y_test)\n",
        "\n",
        "    cql = CQLlite(in_dim, num_classes, lr=1e-3, eps=0.1)\n",
        "    for _ in range(min(2000, Xtr_dense.shape[0]*2)):\n",
        "        i = np.random.randint(0, Xtr_dense.shape[0])\n",
        "        x = Xtr_dense[i].unsqueeze(0)\n",
        "        ytrue = int(y_train[i])\n",
        "        a = ytrue\n",
        "        r = torch.tensor([compute_reward(ytrue, a)], dtype=torch.float32)\n",
        "        xn = Xtr_dense[np.random.randint(0, Xtr_dense.shape[0])].unsqueeze(0)\n",
        "        cql.update(x, a, r, xn, done=True)\n",
        "        cql.soft_update(0.01)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = cql.q(Xte_dense)\n",
        "        pred_cql = logits.argmax(dim=-1).cpu().numpy()\n",
        "\n",
        "    cm_cql, rep_cql = evaluate_policy(pred_cql, y_test)\n",
        "\n",
        "    results = {\n",
        "        \"behavior_cloning\": {\"confusion_matrix\": cm_bc.tolist(), \"report\": rep_bc},\n",
        "        \"cql_lite\": {\"confusion_matrix\": cm_cql.tolist(), \"report\": rep_cql},\n",
        "    }\n",
        "    return results\n",
        "\n",
        "def explain_policy_with_shap(policy_net, X_background, X_explain, topK=10):\n",
        "    if not SHAP_AVAILABLE:\n",
        "        return None, None\n",
        "    def f_predict(x_np):\n",
        "        x_t = torch.tensor(x_np, dtype=torch.float32)\n",
        "        with torch.no_grad():\n",
        "            logp = policy_net(x_t)\n",
        "            return torch.exp(logp).numpy()  # probabilities\n",
        "    bg_idx = np.random.choice(X_background.shape[0], size=min(50, X_background.shape[0]), replace=False)\n",
        "    bg = X_background[bg_idx].numpy()\n",
        "    explainer = shap.KernelExplainer(f_predict, bg, link=\"identity\")\n",
        "    ex_idx = np.random.choice(X_explain.shape[0], size=min(25, X_explain.shape[0]), replace=False)\n",
        "    xex = X_explain[ex_idx].numpy()\n",
        "    shap_values = explainer.shap_values(xex, nsamples=100)\n",
        "    # Save SHAP arrays\n",
        "    np.save(os.path.join(OUTDIR, \"shap_values.npy\"), shap_values, allow_pickle=True)\n",
        "    np.save(os.path.join(OUTDIR, \"shap_examples.npy\"), xex, allow_pickle=True)\n",
        "    return shap_values, xex\n",
        "\n",
        "def distill_policy_to_tree(policy_net, X_csr, y_true, max_depth=4):\n",
        "    Xd = batch_csr_to_torch(X_csr).numpy()\n",
        "    with torch.no_grad():\n",
        "        policy_probs = torch.exp(policy_net(torch.tensor(Xd, dtype=torch.float32))).numpy()\n",
        "    pseudo_labels = np.argmax(policy_probs, axis=1)\n",
        "    tree = DecisionTreeClassifier(max_depth=max_depth, random_state=SEED)\n",
        "    tree.fit(Xd, pseudo_labels)\n",
        "    pred = tree.predict(batch_csr_to_torch(X_test).numpy())\n",
        "    cm, rep = evaluate_policy(pred, y_test)\n",
        "    with open(os.path.join(OUTDIR, \"surrogate_tree_metrics.json\"), \"w\") as f:\n",
        "        json.dump({\"confusion_matrix\": cm.tolist(), \"report\": rep}, f, indent=2)\n",
        "    rules = export_text(tree, feature_names=[f\"f{i}\" for i in range(Xd.shape[1])])\n",
        "    with open(os.path.join(OUTDIR, \"surrogate_tree_rules.txt\"), \"w\") as f:\n",
        "        f.write(rules)\n",
        "    return tree, rules\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    summary = {}\n",
        "\n",
        "    summary[\"non_contextual_bandits\"] = train_non_contextual_bandits()\n",
        "\n",
        "    summary[\"contextual_bandits\"] = train_contextual_bandits()\n",
        "\n",
        "    deep_results, policy_for_xai, Xtr_d, Xte_d = train_deep_rl()\n",
        "    summary[\"deep_rl\"] = deep_results\n",
        "\n",
        "    summary[\"offline_rl\"] = train_offline_rl()\n",
        "\n",
        "    try:\n",
        "        shap_vals, shap_x = explain_policy_with_shap(policy_for_xai, Xtr_d, Xte_d)\n",
        "        summary[\"shap_saved\"] = SHAP_AVAILABLE\n",
        "    except Exception as e:\n",
        "        summary[\"shap_error\"] = str(e)\n",
        "\n",
        "    try:\n",
        "        tree, rules = distill_policy_to_tree(policy_for_xai, X_train, y_train)\n",
        "        summary[\"surrogate_tree\"] = \"ok\"\n",
        "    except Exception as e:\n",
        "        summary[\"surrogate_tree_error\"] = str(e)\n",
        "\n",
        "    with open(os.path.join(OUTDIR, \"RUN_SUMMARY.json\"), \"w\") as f:\n",
        "        json.dump(summary, f, indent=2)\n",
        "\n",
        "    print(\"Done. Artifacts in:\", OUTDIR)"
      ]
    }
  ]
}