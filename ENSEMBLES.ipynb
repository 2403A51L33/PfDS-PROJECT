{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6GbFbOQPJJRWgFQivHsUa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2403A51L33/PfDS-PROJECT/blob/main/ENSEMBLES.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7YNs561lTUY",
        "outputId": "a66c32b6-fc5b-47c9-eedb-82431fdd7d42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training base model: logreg\n",
            "  logreg macro-F1: 0.3344953782305226\n",
            "Training base model: svm\n",
            "  svm macro-F1: 0.3025114098926853\n",
            "Training base model: rf\n",
            "  rf macro-F1: 0.32921622135331813\n",
            "Training base model: et\n",
            "  et macro-F1: 0.36134290546055253\n",
            "Training base model: cnb\n",
            "  cnb macro-F1: 0.35690058479532166\n",
            "Tuning Voting weights...\n",
            "Best voting weights: {'weights': [2, 2, 1, 1, 1]}\n",
            "Voting macro-F1: 0.3628403394850763\n",
            "Training Stacking ensemble...\n",
            "Stacking macro-F1: 0.33994565217391304\n",
            "Computing permutation importance for Stacking...\n",
            "\n",
            "Done. Artifacts saved in: ./ensemble_outputs\n",
            "Top files to check:\n",
            " - metrics_.json, confusion_matrix_.json (each base model)\n",
            " - metrics_voting.json, metrics_stacking.json\n",
            " - permutation_importance_stacking.csv\n",
            " - feature_importances_rf.csv / feature_importances_et.csv (if available)\n",
            " - feature_names.txt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import math\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, VotingClassifier, StackingClassifier\n",
        "from sklearn.inspection import permutation_importance\n",
        "from scipy.stats import randint as sp_randint, uniform as sp_uniform\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED)\n",
        "\n",
        "DATA_PATH = \"/content/realistic_drug_labels_side_effects.csv\"\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    alt = \"./realistic_drug_labels_side_effects.csv\"\n",
        "    if os.path.exists(alt):\n",
        "        DATA_PATH = alt\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"CSV not found at {DATA_PATH} or {alt}\")\n",
        "\n",
        "OUTDIR = \"./ensemble_outputs\"\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "TEXT_COLS = [c for c in [\"indications\", \"side_effects\", \"contraindications\", \"warnings\"] if c in df.columns]\n",
        "NUM_COLS  = [c for c in [\"dosage_mg\", \"price_usd\", \"approval_year\"] if c in df.columns]\n",
        "CAT_COLS  = [c for c in [\"drug_class\", \"administration_route\", \"approval_status\", \"manufacturer\"] if c in df.columns]\n",
        "\n",
        "if len(TEXT_COLS) == 0:\n",
        "    TEXT_COLS = [c for c in df.columns if df[c].dtype == object and c != \"side_effect_severity\"]\n",
        "\n",
        "for c in TEXT_COLS: df[c] = df[c].fillna(\"\")\n",
        "for c in NUM_COLS:  df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "for c in CAT_COLS:  df[c] = df[c].astype(str).fillna(\"UNK\")\n",
        "\n",
        "def _to_num(v):\n",
        "    try:\n",
        "        return float(v)\n",
        "    except:\n",
        "        m = {\"low\":0, \"mild\":0, \"moderate\":1, \"medium\":1, \"high\":2, \"severe\":2}\n",
        "        return m.get(str(v).strip().lower(), np.nan)\n",
        "\n",
        "y_raw = df[\"side_effect_severity\"]\n",
        "if y_raw.dtype.kind in \"ifu\":\n",
        "    q = np.quantile(y_raw, [0.33, 0.66])\n",
        "    y = y_raw.apply(lambda v: 0 if v <= q[0] else (1 if v <= q[1] else 2)).astype(int).values\n",
        "else:\n",
        "    tmp = y_raw.apply(_to_num)\n",
        "    if tmp.isna().mean() < 0.5:\n",
        "        q = np.quantile(tmp.fillna(tmp.median()), [0.33, 0.66])\n",
        "        y = tmp.fillna(tmp.median()).apply(lambda v: 0 if v <= q[0] else (1 if v <= q[1] else 2)).astype(int).values\n",
        "    else:\n",
        "        cats = {k:i for i,k in enumerate(sorted(y_raw.astype(str).unique()))}\n",
        "        y = y_raw.astype(str).map(cats).values % 3\n",
        "\n",
        "CLASS_NAMES = [\"low\",\"moderate\",\"high\"]\n",
        "NUM_CLASSES = 3\n",
        "\n",
        "def concat_text_columns(X):\n",
        "    return X[TEXT_COLS].apply(lambda r: \" \".join(map(str, r.values)), axis=1)\n",
        "\n",
        "text_union = Pipeline([\n",
        "    (\"text_concat\", FunctionTransformer(concat_text_columns, validate=False)),\n",
        "    (\"tfidf\", TfidfVectorizer(max_features=50000, ngram_range=(1,2), min_df=2))\n",
        "])\n",
        "\n",
        "num_proc = Pipeline([\n",
        "    (\"impute\", FunctionTransformer(lambda x: np.nan_to_num(x, nan=np.nanmedian(x, axis=0)), accept_sparse=True)),\n",
        "    (\"scale\", StandardScaler(with_mean=False))\n",
        "])\n",
        "\n",
        "cat_proc = Pipeline([\n",
        "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", min_frequency=5))\n",
        "])\n",
        "\n",
        "pre = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"text\", text_union, TEXT_COLS),\n",
        "        (\"num\", num_proc, NUM_COLS) if len(NUM_COLS)>0 else (\"num\", \"drop\", []),\n",
        "        (\"cat\", cat_proc, CAT_COLS) if len(CAT_COLS)>0 else (\"cat\", \"drop\", []),\n",
        "    ],\n",
        "    sparse_threshold=0.3\n",
        ")\n",
        "\n",
        "X = df[TEXT_COLS + NUM_COLS + CAT_COLS]\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=SEED, stratify=y\n",
        ")\n",
        "\n",
        "classes = np.unique(y_train)\n",
        "cw = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train)\n",
        "CLASS_WEIGHTS = {c:w for c,w in zip(classes, cw)}\n",
        "\n",
        "logreg = Pipeline([\n",
        "    (\"pre\", pre),\n",
        "    (\"clf\", LogisticRegression(\n",
        "        class_weight=\"balanced\", solver=\"saga\", max_iter=2000, C=2.0, n_jobs=1, random_state=SEED))\n",
        "])\n",
        "\n",
        "svm_base = Pipeline([\n",
        "    (\"pre\", pre),\n",
        "    (\"svm\", LinearSVC(class_weight=\"balanced\", C=1.0, random_state=SEED))\n",
        "])\n",
        "svm = Pipeline([\n",
        "    (\"pre\", pre),\n",
        "    (\"cal\", CalibratedClassifierCV(estimator=LinearSVC(\n",
        "        class_weight=\"balanced\", C=1.0, random_state=SEED\n",
        "    ), method=\"sigmoid\", cv=3))\n",
        "])\n",
        "\n",
        "rf = Pipeline([\n",
        "    (\"pre\", pre),\n",
        "    (\"clf\", RandomForestClassifier(\n",
        "        n_estimators=400, max_depth=None, min_samples_split=2,\n",
        "        class_weight=\"balanced_subsample\", n_jobs=-1, random_state=SEED))\n",
        "])\n",
        "\n",
        "et = Pipeline([\n",
        "    (\"pre\", pre),\n",
        "    (\"clf\", ExtraTreesClassifier(\n",
        "        n_estimators=600, max_depth=None, min_samples_split=2,\n",
        "        class_weight=\"balanced\", n_jobs=-1, random_state=SEED))\n",
        "])\n",
        "\n",
        "cnb = Pipeline([\n",
        "    (\"pre\", pre),\n",
        "    (\"clf\", ComplementNB(alpha=0.3))\n",
        "])\n",
        "\n",
        "\n",
        "BASE_MODELS = {\n",
        "    \"logreg\": logreg,\n",
        "    \"svm\": svm,\n",
        "    \"rf\": rf,\n",
        "    \"et\": et,\n",
        "    \"cnb\": cnb\n",
        "}\n",
        "\n",
        "for name, pipe in BASE_MODELS.items():\n",
        "    print(f\"Training base model: {name}\")\n",
        "    pipe.fit(X_train, y_train)\n",
        "    y_pred = pipe.predict(X_test)\n",
        "    rep = classification_report(y_test, y_pred, target_names=CLASS_NAMES, output_dict=True, zero_division=0)\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=[0,1,2]).tolist()\n",
        "    with open(os.path.join(OUTDIR, f\"metrics_{name}.json\"), \"w\") as f:\n",
        "        json.dump(rep, f, indent=2)\n",
        "    with open(os.path.join(OUTDIR, f\"confusion_matrix_{name}.json\"), \"w\") as f:\n",
        "        json.dump(cm, f, indent=2)\n",
        "    print(f\"  {name} macro-F1:\", rep[\"macro avg\"][\"f1-score\"])\n",
        "\n",
        "voters = []\n",
        "for name in [\"logreg\",\"svm\",\"rf\",\"et\",\"cnb\"]:\n",
        "    if name in BASE_MODELS:\n",
        "        voters.append((name, BASE_MODELS[name].steps[-1][1] if isinstance(BASE_MODELS[name], Pipeline) else BASE_MODELS[name]))\n",
        "\n",
        "voting = VotingClassifier(\n",
        "    estimators=[\n",
        "        (\"logreg\", logreg),\n",
        "        (\"svm\", svm),\n",
        "        (\"rf\", rf),\n",
        "        (\"et\", et),\n",
        "        (\"cnb\", cnb)\n",
        "    ],\n",
        "    voting=\"soft\",\n",
        "    weights=[2,2,2,2,1],\n",
        "    n_jobs=-1,\n",
        "    flatten_transform=True\n",
        ")\n",
        "param_dist = {\n",
        "    \"weights\": [\n",
        "        [a,b,c,d,e] for a in [1,2,3]\n",
        "                    for b in [1,2,3]\n",
        "                    for c in [1,2,3]\n",
        "                    for d in [1,2,3]\n",
        "                    for e in [1,2,3]\n",
        "    ]\n",
        "}\n",
        "sampled = random.sample(param_dist[\"weights\"], k=min(25, len(param_dist[\"weights\"])))\n",
        "search = RandomizedSearchCV(\n",
        "    voting, param_distributions={\"weights\": [w for w in sampled]},\n",
        "    n_iter=len(sampled), scoring=\"f1_macro\", cv=3, n_jobs=-1, random_state=SEED, verbose=0\n",
        ")\n",
        "print(\"Tuning Voting weights...\")\n",
        "search.fit(X_train, y_train)\n",
        "voting_best = search.best_estimator_\n",
        "print(\"Best voting weights:\", search.best_params_)\n",
        "\n",
        "y_pred_v = voting_best.predict(X_test)\n",
        "rep_v = classification_report(y_test, y_pred_v, target_names=CLASS_NAMES, output_dict=True, zero_division=0)\n",
        "cm_v = confusion_matrix(y_test, y_pred_v, labels=[0,1,2]).tolist()\n",
        "with open(os.path.join(OUTDIR, \"metrics_voting.json\"), \"w\") as f:\n",
        "    json.dump(rep_v, f, indent=2)\n",
        "with open(os.path.join(OUTDIR, \"confusion_matrix_voting.json\"), \"w\") as f:\n",
        "    json.dump(cm_v, f, indent=2)\n",
        "print(\"Voting macro-F1:\", rep_v[\"macro avg\"][\"f1-score\"])\n",
        "\n",
        "stack = StackingClassifier(\n",
        "    estimators=[\n",
        "        (\"logreg\", logreg),\n",
        "        (\"svm\", svm),\n",
        "        (\"rf\", rf),\n",
        "        (\"et\", et),\n",
        "        (\"cnb\", cnb)\n",
        "    ],\n",
        "    final_estimator=LogisticRegression(solver=\"lbfgs\", max_iter=2000, class_weight=\"balanced\"),\n",
        "    stack_method=\"predict_proba\",\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    passthrough=False\n",
        ")\n",
        "print(\"Training Stacking ensemble...\")\n",
        "stack.fit(X_train, y_train)\n",
        "y_pred_s = stack.predict(X_test)\n",
        "rep_s = classification_report(y_test, y_pred_s, target_names=CLASS_NAMES, output_dict=True, zero_division=0)\n",
        "cm_s = confusion_matrix(y_test, y_pred_s, labels=[0,1,2]).tolist()\n",
        "with open(os.path.join(OUTDIR, \"metrics_stacking.json\"), \"w\") as f:\n",
        "    json.dump(rep_s, f, indent=2)\n",
        "with open(os.path.join(OUTDIR, \"confusion_matrix_stacking.json\"), \"w\") as f:\n",
        "    json.dump(cm_s, f, indent=2)\n",
        "print(\"Stacking macro-F1:\", rep_s[\"macro avg\"][\"f1-score\"])\n",
        "\n",
        "def get_feature_names(preprocessor: ColumnTransformer):\n",
        "    feature_names = []\n",
        "    for name, transformer, cols in preprocessor.transformers_:\n",
        "        if name == \"remainder\":\n",
        "            continue\n",
        "        if transformer == \"drop\":\n",
        "            continue\n",
        "        if hasattr(transformer, \"named_steps\"):\n",
        "            last = list(transformer.named_steps.values())[-1]\n",
        "\n",
        "            if isinstance(last, TfidfVectorizer):\n",
        "                feature_names += [f\"text__{t}\" for t in last.get_feature_names_out()]\n",
        "\n",
        "            elif isinstance(last, OneHotEncoder):\n",
        "                try:\n",
        "                    ohe = last\n",
        "                except Exception:\n",
        "\n",
        "                    for step in transformer.named_steps.values():\n",
        "                        if isinstance(step, OneHotEncoder):\n",
        "                            ohe = step; break\n",
        "                if isinstance(cols, list):\n",
        "                    col_names = cols\n",
        "                else:\n",
        "                    col_names = [c for c in cols]\n",
        "                ohe_names = list(ohe.get_feature_names_out(col_names))\n",
        "                feature_names += [f\"cat__{t}\" for t in ohe_names]\n",
        "            else:\n",
        "\n",
        "                if isinstance(cols, list) and len(cols)>0:\n",
        "                    feature_names += [f\"num__{c}\" for c in cols]\n",
        "        else:\n",
        "\n",
        "            if isinstance(transformer, TfidfVectorizer):\n",
        "                feature_names += [f\"text__{t}\" for t in transformer.get_feature_names_out()]\n",
        "            elif isinstance(transformer, OneHotEncoder):\n",
        "                ohe_names = list(transformer.get_feature_names_out(cols))\n",
        "                feature_names += [f\"cat__{t}\" for t in ohe_names]\n",
        "            else:\n",
        "                if isinstance(cols, list) and len(cols)>0:\n",
        "                    feature_names += [f\"num__{c}\" for c in cols]\n",
        "    return np.array(feature_names)\n",
        "\n",
        "reference_pre = pre\n",
        "\n",
        "feat_names = None\n",
        "try:\n",
        "    pre_fitted = BASE_MODELS[\"logreg\"].named_steps[\"pre\"]\n",
        "    feat_names = get_feature_names(pre_fitted)\n",
        "    with open(os.path.join(OUTDIR, \"feature_names.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        for n in feat_names:\n",
        "            f.write(n + \"\\n\")\n",
        "except Exception as e:\n",
        "    print(\"Feature name extraction failed:\", e)\n",
        "\n",
        "try:\n",
        "    print(\"Computing permutation importance for Stacking...\")\n",
        "    pi = permutation_importance(stack, X_test, y_test, n_repeats=10, random_state=SEED, scoring=\"f1_macro\", n_jobs=-1)\n",
        "    imp = pd.DataFrame({\"feature\": np.arange(len(pi.importances_mean)),\n",
        "                        \"importance_mean\": pi.importances_mean,\n",
        "                        \"importance_std\":  pi.importances_std})\n",
        "    if feat_names is not None and len(feat_names) == imp.shape[0]:\n",
        "        imp[\"feature\"] = feat_names\n",
        "    imp.sort_values(\"importance_mean\", ascending=False).to_csv(os.path.join(OUTDIR, \"permutation_importance_stacking.csv\"), index=False)\n",
        "except Exception as e:\n",
        "    print(\"Permutation importance failed:\", e)\n",
        "\n",
        "def dump_tree_importances(name, pipe):\n",
        "    try:\n",
        "        clf = pipe.named_steps[\"clf\"]\n",
        "        if hasattr(clf, \"feature_importances_\"):\n",
        "            pre_fit = pipe.named_steps[\"pre\"]\n",
        "            names = get_feature_names(pre_fit)\n",
        "            imp = pd.DataFrame({\"feature\": names, \"importance\": clf.feature_importances_})\n",
        "            imp.sort_values(\"importance\", ascending=False).to_csv(os.path.join(OUTDIR, f\"feature_importances_{name}.csv\"), index=False)\n",
        "    except Exception as e:\n",
        "        print(f\"{name} importances failed:\", e)\n",
        "\n",
        "dump_tree_importances(\"rf\", rf)\n",
        "dump_tree_importances(\"et\", et)\n",
        "\n",
        "def save_summary(tag, report, cm):\n",
        "    summary = {\n",
        "        \"macro_f1\": report[\"macro avg\"][\"f1-score\"],\n",
        "        \"weighted_f1\": report[\"weighted avg\"][\"f1-score\"],\n",
        "        \"per_class\": {k: report[k] for k in [\"low\",\"moderate\",\"high\"] if k in report},\n",
        "        \"confusion_matrix\": cm\n",
        "    }\n",
        "    with open(os.path.join(OUTDIR, f\"summary_{tag}.json\"), \"w\") as f:\n",
        "        json.dump(summary, f, indent=2)\n",
        "\n",
        "save_summary(\"voting\", rep_v, cm_v)\n",
        "save_summary(\"stacking\", rep_s, cm_s)\n",
        "\n",
        "def get_probs(model, X):\n",
        "    try:\n",
        "        return model.predict_proba(X)\n",
        "    except Exception:\n",
        "        pred = model.predict(X)\n",
        "        P = np.zeros((len(pred), NUM_CLASSES))\n",
        "        P[np.arange(len(pred)), pred] = 1.0\n",
        "        return P\n",
        "\n",
        "np.save(os.path.join(OUTDIR, \"oof_probs_voting.npy\"), get_probs(voting_best, X_test))\n",
        "np.save(os.path.join(OUTDIR, \"oof_probs_stacking.npy\"), get_probs(stack, X_test))\n",
        "\n",
        "print(\"\\nDone. Artifacts saved in:\", OUTDIR)\n",
        "print(\"Top files to check:\")\n",
        "print(\" - metrics_.json, confusion_matrix_.json (each base model)\")\n",
        "print(\" - metrics_voting.json, metrics_stacking.json\")\n",
        "print(\" - permutation_importance_stacking.csv\")\n",
        "print(\" - feature_importances_rf.csv / feature_importances_et.csv (if available)\")\n",
        "print(\" - feature_names.txt\")"
      ]
    }
  ]
}